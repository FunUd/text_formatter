import langextract as lx
import textwrap
import os
from pathlib import Path
from dotenv import load_dotenv
import logging
from datetime import datetime

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

class DebugLogger:
    def __init__(self):
        self._log_file = None
        self.logger = logging.getLogger("debug")
        self.logger.setLevel(logging.DEBUG)
        self._handler = None

    @property
    def log_file(self):
        return self._log_file

    @log_file.setter
    def log_file(self, path):
        # ç¾åœ¨ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’å‰Šé™¤
        if self._handler:
            self.logger.removeHandler(self._handler)
            self._handler = None

        self._log_file = path
        if path:
            # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ä½œæˆ
            self._handler = logging.FileHandler(path, mode='w', encoding='utf-8')
            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            self._handler.setFormatter(formatter)
            self.logger.addHandler(self._handler)

    def debug(self, message):
        if self._handler:
            self.logger.debug(message)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªãƒ‡ãƒãƒƒã‚°ãƒ­ã‚¬ãƒ¼ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
debug_logger = DebugLogger()

# 1. Define the prompt and extraction rules
prompt = textwrap.dedent("""\
                            ä»¥ä¸‹ã®ãƒ¬ãƒãƒ¼ãƒˆã‹ã‚‰ã€æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

                            é‡è¦ï¼šextraction_textã«ã¯å…¥åŠ›ã‹ã‚‰ã®æ­£ç¢ºãªãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

                            ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„:
                            "extractions": [
                                { ... }
                            ]

                            é‡è¦ï¼š'extractions'ã‚­ãƒ¼ã¯å‡ºåŠ›ã«å¿…ãšå«ã‚ã¦ãã ã•ã„ã€‚"""
                        )

# 2. Provide a high-quality example to guide the model
examples = [
    # å¸‚å ´åˆ†æãƒ¬ãƒãƒ¼ãƒˆã®ä¾‹
    lx.data.ExampleData(
        text=textwrap.dedent("""
                            å¸‚å ´å‹•å‘åˆ†æãƒ¬ãƒãƒ¼ãƒˆï¼šAIãƒ»æ©Ÿæ¢°å­¦ç¿’å¸‚å ´ 2025å¹´ç¬¬2å››åŠæœŸ
                            
                            å¸‚å ´è¦æ¨¡ï¼š
                            - ã‚°ãƒ­ãƒ¼ãƒãƒ«å¸‚å ´ï¼š2,850å„„ç±³ãƒ‰ãƒ«ï¼ˆå‰å¹´æ¯”+18%ï¼‰
                            - å›½å†…å¸‚å ´ï¼š3.2å…†å††ï¼ˆå‰å¹´æ¯”+15%ï¼‰
                            
                            æˆé•·ç‡äºˆæ¸¬ï¼š
                            - 2025å¹´ï¼š+18%
                            - 2026å¹´ï¼š+22%
                            - 2027å¹´ï¼š+25%
                            
                            ä¸»è¦ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼š
                            1. TechCorpï¼ˆå¸‚å ´ã‚·ã‚§ã‚¢28%ï¼‰
                            2. AIã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚ºï¼ˆå¸‚å ´ã‚·ã‚§ã‚¢22%ï¼‰
                            3. DataMindï¼ˆå¸‚å ´ã‚·ã‚§ã‚¢15%ï¼‰
                            
                            æˆé•·è¦å› ï¼š
                            - ãƒ‡ã‚¸ã‚¿ãƒ«ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã®åŠ é€Ÿ
                            - è‡ªå‹•åŒ–éœ€è¦ã®å¢—åŠ 
                            - ã‚¯ãƒ©ã‚¦ãƒ‰AIã®æ™®åŠ
                            
                            ãƒªã‚¹ã‚¯è¦å› ï¼š
                            - äººæä¸è¶³
                            - ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼è¦åˆ¶
                            - æŠ€è¡“æ¨™æº–åŒ–ã®é…ã‚Œ
                        """),
        extractions=[
            lx.data.Extraction(
                extraction_class="market_size",
                extraction_text="ã‚°ãƒ­ãƒ¼ãƒãƒ«å¸‚å ´ï¼š2,850å„„ç±³ãƒ‰ãƒ«ï¼ˆå‰å¹´æ¯”+18%ï¼‰",
                attributes={
                    "market_type": "ã‚°ãƒ­ãƒ¼ãƒãƒ«",
                    "size": "2,850å„„ç±³ãƒ‰ãƒ«",
                    "growth_rate": "+18%",
                    "year": "2025",
                    "currency": "ç±³ãƒ‰ãƒ«"
                }
            ),
            lx.data.Extraction(
                extraction_class="market_size",
                extraction_text="å›½å†…å¸‚å ´ï¼š3.2å…†å††ï¼ˆå‰å¹´æ¯”+15%ï¼‰",
                attributes={
                    "market_type": "å›½å†…",
                    "size": "3.2å…†å††",
                    "growth_rate": "+15%",
                    "year": "2025",
                    "currency": "å††"
                }
            ),
            lx.data.Extraction(
                extraction_class="growth_forecast",
                extraction_text="2025å¹´ï¼š+18%\n2026å¹´ï¼š+22%\n2027å¹´ï¼š+25%",
                attributes={
                    "forecasts": [
                        {"year": "2025", "rate": "+18%"},
                        {"year": "2026", "rate": "+22%"},
                        {"year": "2027", "rate": "+25%"}
                    ]
                }
            ),
            lx.data.Extraction(
                extraction_class="market_player",
                extraction_text="1. TechCorpï¼ˆå¸‚å ´ã‚·ã‚§ã‚¢28%ï¼‰",
                attributes={
                    "company_name": "TechCorp",
                    "market_share": "28%",
                    "rank": 1
                }
            ),
            lx.data.Extraction(
                extraction_class="market_player",
                extraction_text="2. AIã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚ºï¼ˆå¸‚å ´ã‚·ã‚§ã‚¢22%ï¼‰",
                attributes={
                    "company_name": "AIã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚º",
                    "market_share": "22%",
                    "rank": 2
                }
            ),
            lx.data.Extraction(
                extraction_class="market_player",
                extraction_text="3. DataMindï¼ˆå¸‚å ´ã‚·ã‚§ã‚¢15%ï¼‰",
                attributes={
                    "company_name": "DataMind",
                    "market_share": "15%",
                    "rank": 3
                }
            ),
            lx.data.Extraction(
                extraction_class="factors",
                extraction_text="æˆé•·è¦å› ï¼š\n- ãƒ‡ã‚¸ã‚¿ãƒ«ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã®åŠ é€Ÿ\n- è‡ªå‹•åŒ–éœ€è¦ã®å¢—åŠ \n- ã‚¯ãƒ©ã‚¦ãƒ‰AIã®æ™®åŠ",
                attributes={
                    "factor_type": "growth",
                    "factors": [
                        "ãƒ‡ã‚¸ã‚¿ãƒ«ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã®åŠ é€Ÿ",
                        "è‡ªå‹•åŒ–éœ€è¦ã®å¢—åŠ ",
                        "ã‚¯ãƒ©ã‚¦ãƒ‰AIã®æ™®åŠ"
                    ]
                }
            ),
            lx.data.Extraction(
                extraction_class="factors",
                extraction_text="ãƒªã‚¹ã‚¯è¦å› ï¼š\n- äººæä¸è¶³\n- ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼è¦åˆ¶\n- æŠ€è¡“æ¨™æº–åŒ–ã®é…ã‚Œ",
                attributes={
                    "factor_type": "risk",
                    "factors": [
                        "äººæä¸è¶³",
                        "ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼è¦åˆ¶",
                        "æŠ€è¡“æ¨™æº–åŒ–ã®é…ã‚Œ"
                    ]
                }
            )
        ]
    ),
    lx.data.ExampleData(
        text=textwrap.dedent("""
                                ä½œæˆæ—¥: 2024-06-15
                                æœ€çµ‚æ›´æ–°æ—¥: 2024-06-20
                                å±±ç”°å¤ªéƒ
                                ã‚ªãƒ¼ãƒˆãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿå™¨å¸‚å ´ã®æ¦‚è¦
        """),
        extractions=[
            lx.data.Extraction(
                extraction_class="date",
                extraction_text="ä½œæˆæ—¥: 2024-06-15",
                attributes={
                    "category": "ä½œæˆæ—¥",
                    "date": "2024-06-15",
                    "target": "ãƒ¬ãƒãƒ¼ãƒˆ"
                }
            ),
            lx.data.Extraction(
                extraction_class="date",
                extraction_text="æœ€çµ‚æ›´æ–°æ—¥: 2024-06-20",
                attributes={
                    "category": "æœ€çµ‚æ›´æ–°æ—¥",
                    "date": "2024-06-20",
                    "target": "ãƒ¬ãƒãƒ¼ãƒˆ"
                }
            ),
            lx.data.Extraction(
                extraction_class="human name",
                extraction_text="ä½œæˆè€…: å±±ç”°å¤ªéƒ",
                attributes={
                    "category": "ä½œæˆè€…",
                    "name": "å±±ç”°å¤ªéƒ",
                }
            ),
            lx.data.Extraction(
                extraction_class="title",
                extraction_text="ã‚ªãƒ¼ãƒˆãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿå™¨å¸‚å ´ã®æ¦‚è¦",
                attributes={
                    "category": "report title",
                    "content": "ã‚ªãƒ¼ãƒˆãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿå™¨å¸‚å ´ã®æ¦‚è¦",
                }
            ),
        ]
    ),
    lx.data.ExampleData(
        text=textwrap.dedent("""
            å¸‚å ´ã‚·ã‚§ã‚¢ï¼ˆä¼æ¥­åˆ¥ãƒ»è£½å“ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥ï¼‰
            å¸‚å ´ã¯ã‚„ã‚„å¯¡å çš„ã§ã€ä¸Šä½5ç¤¾ãŒä¸–ç•Œã‚·ã‚§ã‚¢ã®ç´„45ï½60%ã‚’å ã‚ã¦ã„ã¾ã™
        """),
        extractions=[
            lx.data.Extraction(
                extraction_class="ã‚·ã‚§ã‚¢",
                extraction_text="ä¸Šä½5ç¤¾ãŒä¸–ç•Œã‚·ã‚§ã‚¢ã®ç´„45ï½60%ã‚’å ã‚ã¦ã„ã¾ã™",
                attributes={
                    "company": "ä¸Šä½5ç¤¾",
                    "rate": "ç´„45ï½60%",
                    "application": "N/A",
                    "year": "N/A",
                }
            ),
            lx.data.Extraction(
                extraction_class="numeric_value",
                extraction_text="ä¸Šä½5ç¤¾ãŒä¸–ç•Œã‚·ã‚§ã‚¢ã®ç´„45ï½60%ã‚’å ã‚ã¦ã„ã¾ã™",
                attributes={
                    "value": "ç´„45ï½60%",
                    "unit": "%",
                    "context": "ä¸–ç•Œã‚·ã‚§ã‚¢",
                    "year": "N/A",
                    "target": "ä¸Šä½5ç¤¾"
                }
            ),
        ]
    ),
    lx.data.ExampleData(
        text=textwrap.dedent("""
            ä¸»è¦ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆ¥ã§ã¯ã€å‰µè–¬ãƒ»ãƒã‚¤ã‚ªç ”ç©¶åˆ†é‡ï¼ˆãƒ‰ãƒ©ãƒƒã‚°ãƒ‡ã‚£ã‚¹ã‚«ãƒãƒªãƒ¼ã€ã‚²ãƒãƒŸã‚¯ã‚¹ã€ãƒ—ãƒ­ãƒ†ã‚ªãƒŸã‚¯ã‚¹ãªã©ï¼‰ã‚„
            è‡¨åºŠè¨ºæ–­ï¼ˆè‡¨åºŠåŒ–å­¦åˆ†æã‚„éºä¼å­æ¤œæŸ»ï¼‰ã«ãŠã‘ã‚‹è‡ªå‹•åŒ–ãƒ‹ãƒ¼ã‚ºãŒé«˜ã¾ã£ã¦ã„ã¾ã™
            ã€‚ç‰¹ã«è‡¨åºŠè¨ºæ–­åˆ†é‡ã¯2024å¹´ã«å¸‚å ´ã‚·ã‚§ã‚¢ç´„27%ã‚’å ã‚ã€ä»Šå¾Œã‚‚é«˜é½¢åŒ–ã‚„æ…¢æ€§ç–¾æ‚£å¢—åŠ ã«ä¼´ã„
            æ¤œæŸ»é‡å¢—ã«å¯¾å¿œã—ãŸè‡ªå‹•åŒ–éœ€è¦ãŒè¦‹è¾¼ã¾ã‚Œã¾ã™
        """),
        extractions=[
            lx.data.Extraction(
                extraction_class="needs",
                extraction_text="å‰µè–¬ãƒ»ãƒã‚¤ã‚ªç ”ç©¶åˆ†é‡ï¼ˆãƒ‰ãƒ©ãƒƒã‚°ãƒ‡ã‚£ã‚¹ã‚«ãƒãƒªãƒ¼ã€ã‚²ãƒãƒŸã‚¯ã‚¹ã€ãƒ—ãƒ­ãƒ†ã‚ªãƒŸã‚¯ã‚¹ãªã©ï¼‰ã‚„\nè‡¨åºŠè¨ºæ–­ï¼ˆè‡¨åºŠåŒ–å­¦åˆ†æã‚„éºä¼å­æ¤œæŸ»ï¼‰ã«ãŠã‘ã‚‹è‡ªå‹•åŒ–ãƒ‹ãƒ¼ã‚ºãŒé«˜ã¾ã£ã¦ã„ã¾ã™",
                attributes={
                    "application": "å‰µè–¬ãƒ»ãƒã‚¤ã‚ªç ”ç©¶åˆ†é‡",
                    "needs": "è‡ªå‹•åŒ–ãƒ‹ãƒ¼ã‚º",
                    "trends": "é«˜ã¾ã£ã¦ã„ã‚‹",
                }
            ),
            lx.data.Extraction(
                extraction_class="needs",
                extraction_text="å‰µè–¬ãƒ»ãƒã‚¤ã‚ªç ”ç©¶åˆ†é‡ï¼ˆãƒ‰ãƒ©ãƒƒã‚°ãƒ‡ã‚£ã‚¹ã‚«ãƒãƒªãƒ¼ã€ã‚²ãƒãƒŸã‚¯ã‚¹ã€ãƒ—ãƒ­ãƒ†ã‚ªãƒŸã‚¯ã‚¹ãªã©ï¼‰ã‚„\nè‡¨åºŠè¨ºæ–­ï¼ˆè‡¨åºŠåŒ–å­¦åˆ†æã‚„éºä¼å­æ¤œæŸ»ï¼‰ã«ãŠã‘ã‚‹è‡ªå‹•åŒ–ãƒ‹ãƒ¼ã‚ºãŒé«˜ã¾ã£ã¦ã„ã¾ã™",
                attributes={
                    "application": "è‡¨åºŠè¨ºæ–­",
                    "needs": "è‡ªå‹•åŒ–ãƒ‹ãƒ¼ã‚º",
                    "trends": "é«˜ã¾ã£ã¦ã„ã‚‹",
                }
            ),
            lx.data.Extraction(
                extraction_class="numeric_value",
                extraction_text="ç‰¹ã«è‡¨åºŠè¨ºæ–­åˆ†é‡ã¯2024å¹´ã«å¸‚å ´ã‚·ã‚§ã‚¢ç´„27%ã‚’å ã‚ã€",
                attributes={
                    "value": "ç´„27%",
                    "unit": "%",
                    "context": "å¸‚å ´ã‚·ã‚§ã‚¢",
                    "year": "2024å¹´",
                    "target": "è‡¨åºŠè¨ºæ–­åˆ†é‡"
                }
            ),
            lx.data.Extraction(
                extraction_class="needs",
                extraction_text="ç‰¹ã«è‡¨åºŠè¨ºæ–­åˆ†é‡ã¯2024å¹´ã«å¸‚å ´ã‚·ã‚§ã‚¢ç´„27%ã‚’å ã‚ã€ä»Šå¾Œã‚‚é«˜é½¢åŒ–ã‚„æ…¢æ€§ç–¾æ‚£å¢—åŠ ã«ä¼´ã„\næ¤œæŸ»é‡å¢—ã«å¯¾å¿œã—ãŸè‡ªå‹•åŒ–éœ€è¦ãŒè¦‹è¾¼ã¾ã‚Œã¾ã™",
                attributes={
                    "application": "è‡¨åºŠè¨ºæ–­åˆ†é‡",
                    "needs": "ä»Šå¾Œã‚‚é«˜é½¢åŒ–ã‚„æ…¢æ€§ç–¾æ‚£å¢—åŠ ã«ä¼´ã„\næ¤œæŸ»é‡å¢—ã«å¯¾å¿œã—ãŸè‡ªå‹•åŒ–éœ€è¦ãŒè¦‹è¾¼ã¾ã‚Œã¾ã™",
                    "trends": "è‡ªå‹•åŒ–éœ€è¦ãŒè¦‹è¾¼ã¾ã‚Œã¾ã™",
                }
            ),
        ]
    ),
    lx.data.ExampleData(
        text=textwrap.dedent("""
            å¸‚å ´è¦æ¨¡ã¯2024å¹´ã«ç´„500å„„å††ã€å‰å¹´æ¯”10%å¢—åŠ ã€‚
            ç«¶åˆä¸»è¦ä¼æ¥­ã¯Aç¤¾ã€Bç¤¾ã€Cç¤¾ã§ã€Aç¤¾ã®ã‚·ã‚§ã‚¢ãŒç´„35%ã€‚
        """),
        extractions=[
            lx.data.Extraction(
                extraction_class="numeric_value",
                extraction_text="å¸‚å ´è¦æ¨¡ã¯2024å¹´ã«ç´„500å„„å††",
                attributes={
                    "value": "500å„„å††",
                    "unit": "å††",
                    "context": "å¸‚å ´è¦æ¨¡",
                    "year": "2024å¹´",
                    "target": "N/A"
                }
            ),
            lx.data.Extraction(
                extraction_class="numeric_value",
                extraction_text="å¸‚å ´è¦ç«¶åˆä¸»è¦ä¼æ¥­ã¯Aç¤¾ã€Bç¤¾ã€Cç¤¾ã§ã€Aç¤¾ã®ã‚·ã‚§ã‚¢ãŒç´„35%ã€‚",
                attributes={
                    "value": "ç´„35%",
                    "unit": "%",
                    "context": "ã‚·ã‚§ã‚¢",
                    "year": "2024å¹´",
                    "target": "Aç¤¾"
                }
            ),
        ]
    ),
    lx.data.ExampleData(
        text=textwrap.dedent("""
                            ã‚¹ãƒãƒ¼ãƒˆãƒ©ã‚¤ãƒˆX100(SL-X100)ã‚’æ–°è¦ç™ºå£²ã—ã¾ã—ãŸã€‚
                            è²©å£²ä¾¡æ ¼ã¯12,000å††ï¼ˆç¨è¾¼ï¼‰ã§ã™ã€‚
                            X100ã¯ã€éŸ³å£°æ“ä½œã«å¯¾å¿œã—ã¦ãŠã‚Šã€æ¶ˆè²»é›»åŠ›10Wã€çœã‚¨ãƒãƒ¢ãƒ¼ãƒ‰ã‚’æ­è¼‰ã™ã‚‹ãªã©ã€
                            åˆ©ä¾¿æ€§ã¨ã‚¨ã‚³ã‚’è¿½æ±‚ã—ãŸè£½å“ã§ã™ã€‚
        """),
        extractions=[
            lx.data.Extraction(
                extraction_class="name",
                extraction_text="ã‚¹ãƒãƒ¼ãƒˆãƒ©ã‚¤ãƒˆX100(SL-X100)ã‚’æ–°è¦ç™ºå£²ã—ã¾ã—ãŸã€‚",
                attributes={
                    "product_name": "ã‚¹ãƒãƒ¼ãƒˆãƒ©ã‚¤ãƒˆX100",
                    "model_name": "SL-X100",
                    "category": "ã‚¹ãƒãƒ¼ãƒˆãƒ›ãƒ¼ãƒ ",
                    "subcategory": "ç…§æ˜",
                    "version": "N/A"
                }
            ),
            lx.data.Extraction(
                extraction_class="price",
                extraction_text="è²©å£²ä¾¡æ ¼ã¯12,000å††ï¼ˆç¨è¾¼ï¼‰ã§ã™ã€‚",
                attributes={
                    "base_price": "12,000å††ï¼ˆç¨è¾¼ï¼‰",
                    "subscription": "N/A",
                    "additional_fees": "N/A",
                    "price_type": "one-time"
                }
            ),
            lx.data.Extraction(
                extraction_class="features",
                extraction_text="éŸ³å£°æ“ä½œã«å¯¾å¿œã—ã¦ãŠã‚Šã€æ¶ˆè²»é›»åŠ›10Wã€çœã‚¨ãƒãƒ¢ãƒ¼ãƒ‰ã‚’æ­è¼‰ã™ã‚‹",
                attributes={
                    "core_features": [
                        "éŸ³å£°æ“ä½œå¯¾å¿œ",
                        "çœã‚¨ãƒãƒ¢ãƒ¼ãƒ‰æ­è¼‰"
                    ],
                    "premium_features": "N/A",
                    "performance": "æ¶ˆè²»é›»åŠ›10W"
                }
            ),
            lx.data.Extraction(
                extraction_class="specifications",
                extraction_text="éŸ³å£°æ“ä½œã«å¯¾å¿œã—ã¦ãŠã‚Šã€æ¶ˆè²»é›»åŠ›10Wã€çœã‚¨ãƒãƒ¢ãƒ¼ãƒ‰ã‚’æ­è¼‰ã™ã‚‹",
                attributes={
                    "technical_specs": {
                        "power": "10W"
                    },
                    "connectivity": "N/A",
                    "standards": "N/A",
                    "dimensions": "N/A"
                }
            ),
        ]
    ),
    lx.data.ExampleData(
        text=textwrap.dedent("""
                            AIç”»åƒå‡¦ç†ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã€ŒImageAI Pro Version 2.5ã€ã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã—ãŸã€‚
                            ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æ–™é‡‘ã¯ã€ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ãƒ—ãƒ©ãƒ³ãŒæœˆé¡4,980å††ï¼ˆç¨è¾¼ï¼‰ã€
                            ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒ—ãƒ©ãƒ³ãŒæœˆé¡29,800å††ï¼ˆç¨è¾¼ï¼‰ã¨ãªã‚Šã¾ã™ã€‚
                            
                            ä¸»ãªæ©Ÿèƒ½ï¼š
                            - AIã«ã‚ˆã‚‹è‡ªå‹•ç”»åƒè£œæ­£
                            - ãƒãƒƒãƒå‡¦ç†å¯¾å¿œï¼ˆæœ€å¤§1000æš/åˆ†ï¼‰
                            - ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸é€£æº
                            - APIæä¾›ï¼ˆã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒ—ãƒ©ãƒ³ã®ã¿ï¼‰
        """),
        extractions=[
            lx.data.Extraction(
                extraction_class="name",
                extraction_text="AIç”»åƒå‡¦ç†ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã€ŒImageAI Pro Version 2.5ã€ã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã—ãŸã€‚",
                attributes={
                    "product_name": "ImageAI Pro",
                    "model_name": "N/A",
                    "category": "ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢",
                    "subcategory": "ç”»åƒå‡¦ç†",
                    "version": "2.5"
                }
            ),
            lx.data.Extraction(
                extraction_class="price",
                extraction_text="ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æ–™é‡‘ã¯ã€ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ãƒ—ãƒ©ãƒ³ãŒæœˆé¡4,980å††ï¼ˆç¨è¾¼ï¼‰ã€\nã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒ—ãƒ©ãƒ³ãŒæœˆé¡29,800å††ï¼ˆç¨è¾¼ï¼‰ã¨ãªã‚Šã¾ã™ã€‚",
                attributes={
                    "base_price": "æœˆé¡4,980å††ï¼ˆç¨è¾¼ï¼‰",
                    "subscription": "æœˆé¡",
                    "additional_fees": {
                        "enterprise": "æœˆé¡29,800å††ï¼ˆç¨è¾¼ï¼‰"
                    },
                    "price_type": "subscription"
                }
            ),
            lx.data.Extraction(
                extraction_class="features",
                extraction_text="ä¸»ãªæ©Ÿèƒ½ï¼š\n- AIã«ã‚ˆã‚‹è‡ªå‹•ç”»åƒè£œæ­£\n- ãƒãƒƒãƒå‡¦ç†å¯¾å¿œï¼ˆæœ€å¤§1000æš/åˆ†ï¼‰\n- ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸é€£æº\n- APIæä¾›ï¼ˆã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒ—ãƒ©ãƒ³ã®ã¿ï¼‰",
                attributes={
                    "core_features": [
                        "AIã«ã‚ˆã‚‹è‡ªå‹•ç”»åƒè£œæ­£",
                        "ãƒãƒƒãƒå‡¦ç†å¯¾å¿œ",
                        "ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸é€£æº"
                    ],
                    "premium_features": [
                        "APIæä¾›"
                    ],
                    "performance": "æœ€å¤§1000æš/åˆ†"
                }
            ),
            lx.data.Extraction(
                extraction_class="specifications",
                extraction_text="ãƒãƒƒãƒå‡¦ç†å¯¾å¿œï¼ˆæœ€å¤§1000æš/åˆ†ï¼‰",
                attributes={
                    "technical_specs": {
                        "processing_speed": "1000æš/åˆ†"
                    },
                    "connectivity": "ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸é€£æº",
                    "standards": "N/A",
                    "dimensions": "N/A"
                }
            ),
        ]
    ),
    # IoTè£½å“ã®ä¾‹
    lx.data.ExampleData(
        text=textwrap.dedent("""
                            ã‚¹ãƒãƒ¼ãƒˆãƒ›ãƒ¼ãƒ ãƒãƒ–ã€ŒHomeConnect Pro (HC-P200)ã€ç™ºå£²é–‹å§‹ã®ãŠçŸ¥ã‚‰ã›
                            
                            æœ¬ä½“ä¾¡æ ¼ï¼š35,800å††ï¼ˆç¨è¾¼ï¼‰
                            â€»ã‚¯ãƒ©ã‚¦ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹åˆ©ç”¨æ–™ã¯1å¹´é–“ç„¡æ–™ã€2å¹´ç›®ä»¥é™ã¯å¹´é¡3,600å††ï¼ˆç¨è¾¼ï¼‰
                            
                            ç‰¹å¾´ï¼š
                            - Wi-Fi 6å¯¾å¿œ
                            - Matterè¦æ ¼æº–æ‹ 
                            - æœ€å¤§200å°ã®ãƒ‡ãƒã‚¤ã‚¹æ¥ç¶š
                            - AIæ­è¼‰çœã‚¨ãƒåˆ¶å¾¡
                            - ãƒãƒƒãƒ†ãƒªãƒ¼ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆ4æ™‚é–“ï¼‰
                            
                            å¯¾å¿œè¦æ ¼ï¼š
                            Zigbee 3.0ã€Bluetooth 5.2ã€Thread
        """),
        extractions=[
            lx.data.Extraction(
                extraction_class="name",
                extraction_text="ã‚¹ãƒãƒ¼ãƒˆãƒ›ãƒ¼ãƒ ãƒãƒ–ã€ŒHomeConnect Pro (HC-P200)ã€ç™ºå£²é–‹å§‹ã®ãŠçŸ¥ã‚‰ã›",
                attributes={
                    "product_name": "HomeConnect Pro",
                    "model_name": "HC-P200",
                    "category": "ã‚¹ãƒãƒ¼ãƒˆãƒ›ãƒ¼ãƒ ",
                    "subcategory": "ãƒãƒ–",
                    "version": "N/A"
                }
            ),
            lx.data.Extraction(
                extraction_class="price",
                extraction_text="æœ¬ä½“ä¾¡æ ¼ï¼š35,800å††ï¼ˆç¨è¾¼ï¼‰\nâ€»ã‚¯ãƒ©ã‚¦ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹åˆ©ç”¨æ–™ã¯1å¹´é–“ç„¡æ–™ã€2å¹´ç›®ä»¥é™ã¯å¹´é¡3,600å††ï¼ˆç¨è¾¼ï¼‰",
                attributes={
                    "base_price": "35,800å††ï¼ˆç¨è¾¼ï¼‰",
                    "subscription": "å¹´é¡3,600å††ï¼ˆç¨è¾¼ï¼‰",
                    "additional_fees": "N/A",
                    "price_type": "hybrid"
                }
            ),
            lx.data.Extraction(
                extraction_class="features",
                extraction_text="ç‰¹å¾´ï¼š\n- Wi-Fi 6å¯¾å¿œ\n- Matterè¦æ ¼æº–æ‹ \n- æœ€å¤§200å°ã®ãƒ‡ãƒã‚¤ã‚¹æ¥ç¶š\n- AIæ­è¼‰çœã‚¨ãƒåˆ¶å¾¡\n- ãƒãƒƒãƒ†ãƒªãƒ¼ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆ4æ™‚é–“ï¼‰",
                attributes={
                    "core_features": [
                        "AIæ­è¼‰çœã‚¨ãƒåˆ¶å¾¡",
                        "ãƒãƒƒãƒ†ãƒªãƒ¼ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—",
                        "æœ€å¤§200å°ã®ãƒ‡ãƒã‚¤ã‚¹æ¥ç¶š"
                    ],
                    "premium_features": "N/A",
                    "performance": "ãƒãƒƒãƒ†ãƒªãƒ¼é§†å‹•4æ™‚é–“"
                }
            ),
            lx.data.Extraction(
                extraction_class="specifications",
                extraction_text="å¯¾å¿œè¦æ ¼ï¼š\nZigbee 3.0ã€Bluetooth 5.2ã€Thread",
                attributes={
                    "technical_specs": {
                        "max_devices": "200å°",
                        "backup_time": "4æ™‚é–“"
                    },
                    "connectivity": [
                        "Wi-Fi 6",
                        "Bluetooth 5.2"
                    ],
                    "standards": [
                        "Matter",
                        "Zigbee 3.0",
                        "Thread"
                    ],
                    "dimensions": "N/A"
                }
            ),
        ]
    ),
]

def get_model_config(use_local=True):
    """ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’è¿”ã™é–¢æ•°"""
    if use_local:
        return {
            'model_id': 'gemma:2b-instruct',
            'api_key': None  # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã§ã¯API keyã¯ä¸è¦
        }
    else:
        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            raise ValueError(
                "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã«GEMINI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
            )
        return {
            'model_id': 'gemini-2.5-flash',
            'api_key': api_key
        }

def debug_print(debug_mode, *args, **kwargs):
    """ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ãªå ´åˆã«ã®ã¿ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹"""
    if debug_mode:
        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›
        print(*args, **kwargs)
        # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã«ã‚‚å‡ºåŠ›
        message = " ".join(str(arg) for arg in args)
        debug_logger.debug(message)

def process_text(text, output_prefix, output_dir, use_local=True, debug_mode=False):
    """Process a single text and save the results with the given prefix"""
    start_time = datetime.now()
    
    # Get model configuration
    model_config = get_model_config(use_local)
    
    if debug_mode:
        debug_print(debug_mode, "\n=== Process Start ===")
        debug_print(debug_mode, f"Start time: {start_time.isoformat()}")
        debug_print(debug_mode, f"Output prefix: {output_prefix}")
        debug_print(debug_mode, f"Output directory: {output_dir}")
        debug_print(debug_mode, f"Use local model: {use_local}")
        
        # Input text details
        debug_print(debug_mode, "\n=== Input Text ===")
        debug_print(debug_mode, f"Text length: {len(text)} characters")
        debug_print(debug_mode, "Text content:")
        debug_print(debug_mode, text)
        
        # Prompt and examples
        debug_print(debug_mode, "\n=== Prompt and Examples ===")
        debug_print(debug_mode, "Prompt:")
        debug_print(debug_mode, prompt)
        debug_print(debug_mode, "\nNumber of examples:", len(examples))
        for i, example in enumerate(examples, 1):
            debug_print(debug_mode, f"\nExample {i}:")
            debug_print(debug_mode, f"Input text: {example.text}")
            debug_print(debug_mode, f"Extractions: {example.extractions}")
    
    try:
        # LLMãƒªã‚¯ã‚¨ã‚¹ãƒˆã®è©³ç´°ã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        debug_print(debug_mode, "\n=== Sending request to LLM ===")
        debug_print(debug_mode, f"Using model: {model_config.get('model_id', 'unknown')}")
        debug_print(debug_mode, "Model configuration:")
        for key, value in model_config.items():
            if key != 'api_key':  # APIã‚­ãƒ¼ã¯ãƒ­ã‚°ã«æ®‹ã•ãªã„
                debug_print(debug_mode, f"  {key}: {value}")
        
        request_time = datetime.now()
        debug_print(debug_mode, f"Request time: {request_time.isoformat()}")
        
        # Run the extraction
        result = lx.extract(
            text_or_documents=text,
            prompt_description=prompt,
            examples=examples,
            **model_config
        )
        
        response_time = datetime.now()
        debug_print(debug_mode, f"Response received time: {response_time.isoformat()}")
        debug_print(debug_mode, f"Response time: {response_time - request_time}")
        
        # Print the raw response for debugging
        debug_print(debug_mode, "\n=== Raw LLM Response ===")
        debug_print(debug_mode, f"Response type: {type(result)}")
        debug_print(debug_mode, f"Response content:")
        debug_print(debug_mode, result)
        
        if debug_mode and isinstance(result, dict):
            debug_print(debug_mode, "\n=== Response Analysis ===")
            debug_print(debug_mode, "Response keys:", result.keys())
            
            if 'extractions' in result:
                extractions = result['extractions']
                debug_print(debug_mode, f"Number of extractions: {len(extractions)}")
                for i, extraction in enumerate(extractions, 1):
                    debug_print(debug_mode, f"\nExtraction {i}:")
                    debug_print(debug_mode, f"Class: {extraction.get('extraction_class')}")
                    debug_print(debug_mode, f"Text: {extraction.get('extraction_text')}")
                    debug_print(debug_mode, f"Attributes: {extraction.get('attributes')}")
            else:
                debug_print(debug_mode, "\n!!! WARNING: 'extractions' key not found in response !!!")
                if 'error' in result:
                    debug_print(debug_mode, f"Error from API: {result['error']}")
                    
    except Exception as e:
        error_time = datetime.now()
        error_msg = f"\n!!! ERROR during extraction: {str(e)} !!!"
        print(error_msg)
        if debug_mode:
            debug_print(debug_mode, "\n=== Error Details ===")
            debug_print(debug_mode, f"Error time: {error_time.isoformat()}")
            debug_print(debug_mode, error_msg)
            debug_print(debug_mode, "\nStack trace:")
            import traceback
            debug_print(debug_mode, traceback.format_exc())
        return  # Exit the function if there was an error

    # Create output directory if it doesn't exist
    output_dir.mkdir(parents=True, exist_ok=True)

    # Create output filenames
    jsonl_file = output_dir / f"{output_prefix}_results.jsonl"
    html_file = output_dir / f"{output_prefix}_visualization.html"

    # Save the results to a JSONL file
    if debug_mode:
        debug_print(debug_mode, "\n=== Saving Results ===")
        debug_print(debug_mode, f"JSONL file: {jsonl_file}")
        debug_print(debug_mode, f"HTML file: {html_file}")
    
    lx.io.save_annotated_documents([result], output_name=jsonl_file.name, output_dir=str(output_dir))

    # Generate the visualization from the file
    html_content = lx.visualize(str(jsonl_file))
    with open(html_file, "w", encoding='utf-8') as f:
        if hasattr(html_content, 'data'):
            f.write(html_content.data)  # For Jupyter/Colab
        else:
            f.write(html_content)
    
    completion_message = f"Processed and saved results to {output_dir}/{output_prefix}_*"
    print(completion_message)
    
    if debug_mode:
        end_time = datetime.now()
        debug_print(debug_mode, "\n=== Process Complete ===")
        debug_print(debug_mode, f"End time: {end_time.isoformat()}")
        debug_print(debug_mode, completion_message)
        debug_print(debug_mode, f"Total processing time: {end_time - start_time}")

def main():
    import argparse
    from pathlib import Path
    global debug_logger

    # filter_resultsé–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    # filter_resultsã¯ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…ã§å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€æ˜ç¤ºçš„ãªã‚¤ãƒ³ãƒãƒ¼ãƒˆã¯ä¸è¦

    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è¨­å®š
    parser = argparse.ArgumentParser(description='ä¸å…·åˆãƒã‚±ãƒƒãƒˆæƒ…å ±æŠ½å‡ºãƒ„ãƒ¼ãƒ«')
    parser.add_argument('--online', action='store_true',
                      help='ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã®LLM (Gemini-2.5)ã‚’ä½¿ç”¨ã™ã‚‹')
    parser.add_argument('--debug', action='store_true',
                      help='ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹')
    args = parser.parse_args()
    
    # Define directories
    input_dir = Path("input")
    output_dir = Path("out")
    
    # Create input directory if it doesn't exist
    input_dir.mkdir(exist_ok=True)
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®åˆæœŸåŒ–
    if args.debug:
        debug_logger.log_file = output_dir / "main.log"
        debug_print(True, "\n=== Text Analysis Process Started ===")
        debug_print(True, f"Start time: {datetime.now().isoformat()}")
        debug_print(True, f"Input directory: {input_dir}")
        debug_print(True, f"Output directory: {output_dir}")
        debug_print(True, f"Online mode: {args.online}")
    
    # Process all markdown files in the input directory
    md_files = list(input_dir.glob("*.md"))
    
    if not md_files:
        message = f"No markdown files found in {input_dir}/. Please add some .md files to process."
        print(message)
        if args.debug:
            debug_print(True, f"\n!!! WARNING: {message}")
        return
    
    # ãƒ¢ãƒ‡ãƒ«ã®ç¨®é¡ã‚’è¡¨ç¤º
    model_config = get_model_config(not args.online)
    model_info = f"Using model: {model_config['model_id']}"
    print(model_info)
    if args.debug:
        debug_print(True, f"\n=== Model Configuration ===")
        debug_print(True, model_info)
        debug_print(True, f"Total files to process: {len(md_files)}")
        debug_print(True, "Files to process:")
        for md_file in md_files:
            debug_print(True, f"  - {md_file.name}")
    
    total_files = len(md_files)
    for index, md_file in enumerate(md_files, 1):
            if not md_file.exists():
                print(f"Skipping missing file [{index}/{total_files}]: {md_file.name}")
                continue
            print(f"\nğŸ“„ Processing file [{index}/{total_files}]: {md_file.name}")
            try:
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                output_prefix = md_file.stem
                # --debugæœ‰åŠ¹æ™‚ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°å‡ºåŠ›å…ˆã‚’è¨­å®š
                if args.debug:
                    debug_logger.log_file = output_dir / f"debug_{md_file.stem}.log"
                else:
                    debug_logger.log_file = None
                process_text(content, output_prefix, output_dir, 
                           use_local=not args.online,
                           debug_mode=args.debug)
                result_file = output_dir / f"{output_prefix}_results.jsonl"
                if result_file.exists() and (args.filter_class or args.filter_attribute):
                    filtered = filter_results(
                        result_file,
                        class_name=args.filter_class,
                        attribute_name=args.filter_attribute,
                        attribute_value=args.filter_value
                    )
                    if filtered:
                        filtered_file = output_dir / f"{output_prefix}_filtered_results.jsonl"
                        import json
                        with open(filtered_file, 'w', encoding='utf-8') as f:
                            for result in filtered:
                                json.dump(result, f, ensure_ascii=False)
                                f.write('\n')
                        print(f"Filtered results saved to {filtered_file}")
            except Exception as e:
                print(f"Error processing {md_file}: {str(e)}")

if __name__ == "__main__":
    main()