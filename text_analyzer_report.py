import langextract as lx
import textwrap
import os
from pathlib import Path
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# 1. Define the prompt and extraction rules
prompt = textwrap.dedent("""\
                            ä»¥ä¸‹ã®ãƒ¬ãƒãƒ¼ãƒˆã‹ã‚‰ã€æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

                            é‡è¦ï¼šextraction_textã«ã¯å…¥åŠ›ã‹ã‚‰ã®æ­£ç¢ºãªãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

                            ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„:
                            "extractions": [
                                { ... }
                            ]

                            é‡è¦ï¼š'extractions'ã‚­ãƒ¼ã¯å‡ºåŠ›ã«å¿…ãšå«ã‚ã¦ãã ã•ã„ã€‚"""
                        )

# 2. Provide a high-quality example to guide the model
examples = [
    lx.data.ExampleData(
        text=textwrap.dedent("""
                                ä½œæˆæ—¥: 2024-06-15
                                æœ€çµ‚æ›´æ–°æ—¥: 2024-06-20
                                å±±ç”°å¤ªéƒ
                                ã‚ªãƒ¼ãƒˆãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿå™¨å¸‚å ´ã®æ¦‚è¦
        """),
        extractions=[
            lx.data.Extraction(
                extraction_class="ãƒ¬ãƒãƒ¼ãƒˆæƒ…å ±",
                extraction_text="ä½œæˆæ—¥: 2024-06-15",
                attributes={
                    "creation_date": "2024-06-15",
                    "last_updated_date": "2024-06-20",
                    "author": "å±±ç”°å¤ªéƒ",
                    "title": "ã‚ªãƒ¼ãƒˆãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿå™¨å¸‚å ´ã®æ¦‚è¦",
                }
            ),
        ]
    ),
    lx.data.ExampleData(
        text=textwrap.dedent("""
            å¸‚å ´ã‚·ã‚§ã‚¢ï¼ˆä¼æ¥­åˆ¥ãƒ»è£½å“ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥ï¼‰
            å¸‚å ´ã¯ã‚„ã‚„å¯¡å çš„ã§ã€ä¸Šä½5ç¤¾ãŒä¸–ç•Œã‚·ã‚§ã‚¢ã®ç´„45ï½60%ã‚’å ã‚ã¦ã„ã¾ã™
        """),
        extractions=[
            lx.data.Extraction(
                extraction_class="ã‚·ã‚§ã‚¢",
                extraction_text="å¸‚å ´ã¯ã‚„ã‚„å¯¡å çš„ã§ã€ä¸Šä½5ç¤¾ãŒä¸–ç•Œã‚·ã‚§ã‚¢ã®ç´„45ï½60%ã‚’å ã‚ã¦ã„ã¾ã™",
                attributes={
                    "company": "ä¸Šä½5ç¤¾",
                    "rate": "ç´„45ï½60%",
                    "application": "N/A",
                    "year": "N/A",
                }
            ),
        ]
    ),
    lx.data.ExampleData(
        text=textwrap.dedent("""
            ä¸»è¦ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆ¥ã§ã¯ã€å‰µè–¬ãƒ»ãƒã‚¤ã‚ªç ”ç©¶åˆ†é‡ï¼ˆãƒ‰ãƒ©ãƒƒã‚°ãƒ‡ã‚£ã‚¹ã‚«ãƒãƒªãƒ¼ã€ã‚²ãƒãƒŸã‚¯ã‚¹ã€ãƒ—ãƒ­ãƒ†ã‚ªãƒŸã‚¯ã‚¹ãªã©ï¼‰ã‚„
            è‡¨åºŠè¨ºæ–­ï¼ˆè‡¨åºŠåŒ–å­¦åˆ†æã‚„éºä¼å­æ¤œæŸ»ï¼‰ã«ãŠã‘ã‚‹è‡ªå‹•åŒ–ãƒ‹ãƒ¼ã‚ºãŒé«˜ã¾ã£ã¦ã„ã¾ã™
            ã€‚ç‰¹ã«è‡¨åºŠè¨ºæ–­åˆ†é‡ã¯2024å¹´ã«å¸‚å ´ã‚·ã‚§ã‚¢ç´„27%ã‚’å ã‚ã€ä»Šå¾Œã‚‚é«˜é½¢åŒ–ã‚„æ…¢æ€§ç–¾æ‚£å¢—åŠ ã«ä¼´ã„
            æ¤œæŸ»é‡å¢—ã«å¯¾å¿œã—ãŸè‡ªå‹•åŒ–éœ€è¦ãŒè¦‹è¾¼ã¾ã‚Œã¾ã™
        """),
        extractions=[
            lx.data.Extraction(
                extraction_class="ãƒ‹ãƒ¼ã‚º",
                extraction_text="å‰µè–¬ãƒ»ãƒã‚¤ã‚ªç ”ç©¶åˆ†é‡ï¼ˆãƒ‰ãƒ©ãƒƒã‚°ãƒ‡ã‚£ã‚¹ã‚«ãƒãƒªãƒ¼ã€ã‚²ãƒãƒŸã‚¯ã‚¹ã€ãƒ—ãƒ­ãƒ†ã‚ªãƒŸã‚¯ã‚¹ãªã©ï¼‰ã‚„\nè‡¨åºŠè¨ºæ–­ï¼ˆè‡¨åºŠåŒ–å­¦åˆ†æã‚„éºä¼å­æ¤œæŸ»ï¼‰ã«ãŠã‘ã‚‹è‡ªå‹•åŒ–ãƒ‹ãƒ¼ã‚ºãŒé«˜ã¾ã£ã¦ã„ã¾ã™",
                attributes={
                    "application": "å‰µè–¬ãƒ»ãƒã‚¤ã‚ªç ”ç©¶åˆ†é‡",
                    "needs": "è‡ªå‹•åŒ–ãƒ‹ãƒ¼ã‚º",
                    "trends": "é«˜ã¾ã£ã¦ã„ã‚‹",
                }
            ),
            lx.data.Extraction(
                extraction_class="ãƒ‹ãƒ¼ã‚º",
                extraction_text="å‰µè–¬ãƒ»ãƒã‚¤ã‚ªç ”ç©¶åˆ†é‡ï¼ˆãƒ‰ãƒ©ãƒƒã‚°ãƒ‡ã‚£ã‚¹ã‚«ãƒãƒªãƒ¼ã€ã‚²ãƒãƒŸã‚¯ã‚¹ã€ãƒ—ãƒ­ãƒ†ã‚ªãƒŸã‚¯ã‚¹ãªã©ï¼‰ã‚„\nè‡¨åºŠè¨ºæ–­ï¼ˆè‡¨åºŠåŒ–å­¦åˆ†æã‚„éºä¼å­æ¤œæŸ»ï¼‰ã«ãŠã‘ã‚‹è‡ªå‹•åŒ–ãƒ‹ãƒ¼ã‚ºãŒé«˜ã¾ã£ã¦ã„ã¾ã™",
                attributes={
                    "application": "è‡¨åºŠè¨ºæ–­",
                    "needs": "è‡ªå‹•åŒ–ãƒ‹ãƒ¼ã‚º",
                    "trends": "é«˜ã¾ã£ã¦ã„ã‚‹",
                }
            ),
            lx.data.Extraction(
                extraction_class="ã‚·ã‚§ã‚¢",
                extraction_text="ç‰¹ã«è‡¨åºŠè¨ºæ–­åˆ†é‡ã¯2024å¹´ã«å¸‚å ´ã‚·ã‚§ã‚¢ç´„27%ã‚’å ã‚ã€",
                attributes={
                    "company": "ä¸Šä½5ç¤¾",
                    "rate": "ç´„27%",
                    "application": "è‡¨åºŠè¨ºæ–­åˆ†é‡",
                    "year": "2024å¹´",
                }
            ),
            lx.data.Extraction(
                extraction_class="ãƒ‹ãƒ¼ã‚º",
                extraction_text="ç‰¹ã«è‡¨åºŠè¨ºæ–­åˆ†é‡ã¯2024å¹´ã«å¸‚å ´ã‚·ã‚§ã‚¢ç´„27%ã‚’å ã‚ã€ä»Šå¾Œã‚‚é«˜é½¢åŒ–ã‚„æ…¢æ€§ç–¾æ‚£å¢—åŠ ã«ä¼´ã„\næ¤œæŸ»é‡å¢—ã«å¯¾å¿œã—ãŸè‡ªå‹•åŒ–éœ€è¦ãŒè¦‹è¾¼ã¾ã‚Œã¾ã™",
                attributes={
                    "application": "è‡¨åºŠè¨ºæ–­åˆ†é‡",
                    "needs": "ä»Šå¾Œã‚‚é«˜é½¢åŒ–ã‚„æ…¢æ€§ç–¾æ‚£å¢—åŠ ã«ä¼´ã„\næ¤œæŸ»é‡å¢—ã«å¯¾å¿œã—ãŸè‡ªå‹•åŒ–éœ€è¦ãŒè¦‹è¾¼ã¾ã‚Œã¾ã™",
                    "trends": "è‡ªå‹•åŒ–éœ€è¦ãŒè¦‹è¾¼ã¾ã‚Œã¾ã™",
                }
            ),
        ]
    ),
    lx.data.ExampleData(
        text=textwrap.dedent("""
            å¸‚å ´è¦æ¨¡ã¯2024å¹´ã«ç´„500å„„å††ã€å‰å¹´æ¯”10%å¢—åŠ ã€‚
            ç«¶åˆä¸»è¦ä¼æ¥­ã¯Aç¤¾ã€Bç¤¾ã€Cç¤¾ã§ã€Aç¤¾ã®ã‚·ã‚§ã‚¢ãŒç´„35%ã€‚
        """),
        extractions=[
            lx.data.Extraction(
                extraction_class="å¸‚å ´è¦æ¨¡",
                extraction_text="å¸‚å ´è¦æ¨¡ã¯2024å¹´ã«ç´„500å„„å††ã€å‰å¹´æ¯”10%å¢—åŠ ã€‚",
                attributes={"å¹´": "2024å¹´", "è¦æ¨¡": "ç´„500å„„å††", "æˆé•·ç‡": "å‰å¹´æ¯”10%å¢—åŠ "}
            ),
            lx.data.Extraction(
                extraction_class="ä¼æ¥­",
                extraction_text="ç«¶åˆä¸»è¦ä¼æ¥­ã¯Aç¤¾ã€Bç¤¾ã€Cç¤¾ã§ã€Aç¤¾ã®ã‚·ã‚§ã‚¢ãŒç´„35%ã€‚",
                attributes={"ä¼æ¥­å": "Aç¤¾ã€Bç¤¾ã€Cç¤¾", "ã‚·ã‚§ã‚¢": "Aç¤¾ç´„35%","é–¢ä¿‚": "ç«¶åˆ"}
            ),
        ]
    ),
    lx.data.ExampleData(
        text=textwrap.dedent("""
                            ã‚¹ãƒãƒ¼ãƒˆãƒ©ã‚¤ãƒˆX100(SL-X100)ã‚’æ–°è¦ç™ºå£²ã—ã¾ã—ãŸã€‚
                            è²©å£²ä¾¡æ ¼ã¯12,000å††ï¼ˆç¨è¾¼ï¼‰ã§ã™ã€‚
                            X100ã¯ã€éŸ³å£°æ“ä½œã«å¯¾å¿œã—ã¦ãŠã‚Šã€æ¶ˆè²»é›»åŠ›10Wã€çœã‚¨ãƒãƒ¢ãƒ¼ãƒ‰ã‚’æ­è¼‰ã™ã‚‹ãªã©ã€
                            åˆ©ä¾¿æ€§ã¨ã‚¨ã‚³ã‚’è¿½æ±‚ã—ãŸè£½å“ã§ã™ã€‚
        """),
        extractions=[
            lx.data.Extraction(
                extraction_class="è£½å“æƒ…å ±",
                extraction_text="ã‚¹ãƒãƒ¼ãƒˆãƒ©ã‚¤ãƒˆX100(SL-X100)ã‚’æ–°è¦ç™ºå£²ã—ã¾ã—ãŸã€‚\nè²©å£²ä¾¡æ ¼ã¯12,000å††ï¼ˆç¨è¾¼ï¼‰ã§ã™ã€‚\nX100ã¯ã€éŸ³å£°æ“ä½œã«å¯¾å¿œã—ã¦ãŠã‚Šã€æ¶ˆè²»é›»åŠ›10Wã€çœã‚¨ãƒãƒ¢ãƒ¼ãƒ‰ã‚’æ­è¼‰ã™ã‚‹",
                attributes={
                    "è£½å“å": "ã‚¹ãƒãƒ¼ãƒˆãƒ©ã‚¤ãƒˆX100",
                    "ãƒ¢ãƒ‡ãƒ«å": "SL-X100",
                    "ä¾¡æ ¼": "12,000å††ï¼ˆç¨è¾¼ï¼‰",
                    "ç‰¹å¾´": "éŸ³å£°æ“ä½œå¯¾å¿œã€æ¶ˆè²»é›»åŠ›10Wã€çœã‚¨ãƒãƒ¢ãƒ¼ãƒ‰æ­è¼‰",
                            }
            ),
        ]
    ),
]

def get_model_config(use_local=True):
    """ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’è¿”ã™é–¢æ•°"""
    if use_local:
        return {
            'model_id': 'gemma:2b-instruct',
            'api_key': None  # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã§ã¯API keyã¯ä¸è¦
        }
    else:
        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            raise ValueError(
                "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã«GEMINI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
            )
        return {
            'model_id': 'gemini-2.5-flash',
            'api_key': api_key
        }

def debug_print(debug_mode, *args, **kwargs):
    """ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ãªå ´åˆã«ã®ã¿ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹"""
    if debug_mode:
        print(*args, **kwargs)

def process_text(text, output_prefix, output_dir, use_local=True, debug_mode=False):
    """Process a single text and save the results with the given prefix"""
    # Get model configuration
    model_config = get_model_config(use_local)
    
    try:
        debug_print(debug_mode, "\n=== Sending request to LLM ===")
        debug_print(debug_mode, f"Using model: {model_config.get('model_id', 'unknown')}")
        
        # Run the extraction
        result = lx.extract(
            text_or_documents=text,
            prompt_description=prompt,
            examples=examples,
            **model_config
        )
        
        # Print the raw response for debugging
        debug_print(debug_mode, "\n=== Raw LLM Response ===")
        debug_print(debug_mode, f"Response type: {type(result)}")
        debug_print(debug_mode, f"Response content: {result}")
        
        if debug_mode and isinstance(result, dict):
            debug_print(debug_mode, "\n=== Response Keys ===")
            debug_print(debug_mode, result.keys())
            
            if 'extractions' not in result:
                debug_print(debug_mode, "\n!!! WARNING: 'extractions' key not found in response !!!")
                if 'error' in result:
                    debug_print(debug_mode, f"Error from API: {result['error']}")
                    
    except Exception as e:
        print(f"\n!!! ERROR during extraction: {str(e)} !!!")
        import traceback
        traceback.print_exc()
        return  # Exit the function if there was an error

    # Create output directory if it doesn't exist
    output_dir.mkdir(parents=True, exist_ok=True)

    # Create output filenames
    jsonl_file = output_dir / f"{output_prefix}_results.jsonl"
    html_file = output_dir / f"{output_prefix}_visualization.html"

    # Save the results to a JSONL file
    lx.io.save_annotated_documents([result], output_name=jsonl_file.name, output_dir=str(output_dir))

    # Generate the visualization from the file
    html_content = lx.visualize(str(jsonl_file))
    with open(html_file, "w", encoding='utf-8') as f:
        if hasattr(html_content, 'data'):
            f.write(html_content.data)  # For Jupyter/Colab
        else:
            f.write(html_content)
    
    print(f"Processed and saved results to {output_dir}/{output_prefix}_*")

def main():
    import argparse
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è¨­å®š
    parser = argparse.ArgumentParser(description='ä¸å…·åˆãƒã‚±ãƒƒãƒˆæƒ…å ±æŠ½å‡ºãƒ„ãƒ¼ãƒ«')
    parser.add_argument('--online', action='store_true',
                      help='ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã®LLM (Gemini-2.5)ã‚’ä½¿ç”¨ã™ã‚‹')
    parser.add_argument('--debug', action='store_true',
                      help='ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹')
    args = parser.parse_args()
    
    # Define directories
    input_dir = Path("input")
    output_dir = Path("out")
    
    # Create input directory if it doesn't exist
    input_dir.mkdir(exist_ok=True)
    
    # Process all markdown files in the input directory
    md_files = list(input_dir.glob("*.md"))
    
    if not md_files:
        print(f"No markdown files found in {input_dir}/. Please add some .md files to process.")
        return
    
    # ãƒ¢ãƒ‡ãƒ«ã®ç¨®é¡ã‚’è¡¨ç¤º
    model_config = get_model_config(not args.online)
    print(f"Using model: {model_config['model_id']}")
    
    total_files = len(md_files)
    for index, md_file in enumerate(md_files, 1):
        print(f"\nğŸ“„ Processing file [{index}/{total_files}]: {md_file.name}")
        try:
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Use the filename without extension as the output prefix
            output_prefix = md_file.stem
            process_text(content, output_prefix, output_dir, 
                       use_local=not args.online,
                       debug_mode=args.debug)
            
        except Exception as e:
            print(f"Error processing {md_file}: {str(e)}")

if __name__ == "__main__":
    main()